\chapter{Model Architecture and Experiments}
\phantomsection
\label{ch:experiments}

\section{Experimental Environment and Tools}
\label{sec:environment}
All experiments in this study were conducted on a high-performance workstation running 
Ubuntu 20.04 LTS. The system was equipped with dual NVIDIA RTX 4090 GPUs, each with 
24 GB of VRAM, and 128 GB of system RAM, ensuring ample memory and computational power 
for training large-scalec deep learning models efficiently.

The models were implemented using the PyTorch deep learning framework, with integration of the Hugging Face Transformers library for state-of-the-art model architectures such as TrOCR. GPU acceleration was enabled via CUDA, allowing for fast and parallelized training across the two GPUs.

For experiment tracking and metric logging, MLflow was used. It captured key training 
and evaluation metrics such as character error rate (CER), word error rate (WER), 
training loss, and validation loss in real-time. This facilitated better experiment 
management and reproducibility, especially when comparing multiple model versions or 
hyperparameter configurations.



\section{Model Architecture and Configuration}
\label{sec:architecture}
We propose the end-to-end Khmer \& English OCR solution using a CRAFT model combine
with TrOCR architecture, as shown in Figure \ref{fig:craft-model} and \ref{fig:trocr-model}.
In this section we will describe the details of the model architecture and configuration
from document image to digital text output in whole pipeline.

\subsection{CRAFT for Text Detection}
\label{subsec:craft}

For the text detection stage, we adopted the Character Region Awareness for Text 
Detection (CRAFT) model, which is well-regarded for its ability to detect text at 
the character level rather than relying solely on word-level bounding boxes. 
CRAFT produces dense predictions of character regions and affinity scores, 
enabling it to localize irregular and closely spaced text lines—an essential 
requirement for handling complex scripts like Khmer.

The CRAFT model architecture consists of a VGG16-based backbone followed by a series 
of convolutional layers to produce two output maps:
\begin{itemize}
\item A \textbf{region score map}, indicating the likelihood of each pixel belonging 
to a character region.
\item An \textbf{affinity score map}, capturing the spatial relationships between 
adjacent characters to form text lines.
\end{itemize}

In this study, we fine-tuned a pretrained CRAFT model on a custom Khmer dataset 
composed of synthetic and real-world scene text images. We applied data augmentation 
techniques such as rotation, scaling, blurring, and illumination changes to increase 
the model's robustness. The input images were resized to a fixed height of 768 pixels 
while preserving the aspect ratio.

We used the official implementation of CRAFT with some modifications to better support
Khmer character characteristics, such as tight spacing, stacked glyphs, and diacritic 
marks. The model was trained using Adam optimizer with a learning rate of 1e-4 and batch 
size of 16. Early stopping and validation-based checkpointing were employed to 
prevent overfitting.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/craft_model.png}
    \caption{Illustration of the CRAFT model architecture used for text detection. 
    The model consists of a VGG16-based backbone followed by a series of 
    convolutional layers to produce two output maps: a region score map and 
    an affinity score map. The model is fine-tuned on a custom Khmer dataset 
    composed of synthetic and real-world scene text images. 
    \citet{baek2019craft}}
    \label{fig:craft-model}
\end{figure}

The model has 20,770,466 trainable parameters. The output of the CRAFT detector was then passed to the text recognition 
model (TrOCR), enabling a two-stage pipeline for accurate and end-to-end 
Khmer text reading in general scenes.

\subsection{TrOCR for Text Recognition}
\label{subsec:trocr}

For the text recognition component of the pipeline, we used the \textbf{TrOCR} model, 
a transformer-based OCR system proposed by Microsoft Research. TrOCR stands for 
\textit{Transformer-based Optical Character Recognition}, and it integrates a vision 
encoder with a language decoder in a unified encoder-decoder (Seq2Seq) architecture, 
following the structure of the Vision Transformer (ViT) and pre-trained language models 
like BART.

The TrOCR model takes the cropped text-line image detected by CRAFT and processes it through a \textbf{ViT-based encoder}, which extracts rich visual features. These features are then passed to the \textbf{transformer decoder}, which generates the text sequence token-by-token, using cross-attention to focus on relevant image features while decoding. This allows the model to handle complex scripts like Khmer with better accuracy and context-awareness.

We fine-tuned the base version of TrOCR using the Hugging Face \texttt{transformers} library on our custom synthetic Khmer dataset. During training, we tracked key metrics such as Character Error Rate (CER) and Word Error Rate (WER) using MLflow. The model demonstrated strong generalization across different fonts and text conditions, benefiting from both large-scale pretraining and our domain-specific fine-tuning.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/trocr_model.png}
    \caption{Illustration of the TrOCR model architecture used for text recognition.}
    \label{fig:trocr-model}
\end{figure}

\subsection{The end-to-end pipeline}
\label{subsec:khmer-ocr-pipeline}

        The overall workflow is given in Figure \ref{fig:trocr-inference-full-pipeline}.
It starts with the image-of-text inputs which are English and
Khmer image-text, or even mixing language image-text, the pre-processing
step is converted image into grayscale because we want to down-stream
the task, to make model prediction more accurate. Then the CRAFT model
detects the text region in the image, it's detect text-line based,
we using post processing stop for reordering the detected text-line
to make sure the detected text-line is in the correct order.
After that, the detected text-line is cropped and passed to the TrOCR
model for text recognition. The output of the TrOCR model is the
recognized text. 
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/khmerOCR_inference_full_pipeline.png}
    \caption{End-to-end OCR inference pipeline for converting text images into digital text.}
    \label{fig:trocr-inference-full-pipeline}
\end{figure}

\section{Training Methodology}
\label{sec:training}
This section delves into the training strategies and processes employed to optimize 
the performance and accuracy of the OCR models. We describe the fine-tuning procedures 
for both the CRAFT text detector and TrOCR text recognizer, as well as the key 
hyperparameters and metrics used to evaluate their performance. Additionally, we 
present a discussion on the importance of robust training and the approaches taken 
to ensure the models generalize well across different fonts, text conditions, and 
domains.



\subsection{Fine-tuning Configuration for CRAFT}
\label{subsec:craft-training}

The CRAFT model was fine-tuned on a custom Khmer text dataset 
using weak supervision, leveraging the strengths of annotated 
real-world images. Throughout the training process, a variety 
of data augmentation techniques were employed to enhance the 
model's robustness against font diversity, image noise, and 
other real-world distortions. These augmentations included random 
rotation of text instances by up to 20 degrees, random cropping 
with varying scales and aspect ratios, and horizontal flipping 
to introduce mirrored perspectives. Additionally, color jittering 
was applied, involving simultaneous adjustments in brightness, 
contrast, saturation, and hue, each parameter being varied by a 
factor of 0.2. These transformations enriched the training set 
with diverse visual variations, which in turn helped the model 
generalize more effectively to unseen examples.

To further strengthen the model’s discriminative capabilities, 
we incorporated contrastive learning alongside adversarial training. 
These approaches were particularly beneficial in enabling the model 
to distinguish between visually similar Khmer characters and 
different font styles. Transfer learning also played a pivotal 
role in adapting the model to the Khmer script. Specifically, 
we fine-tuned the pretrained model using a manually annotated 
dataset comprising 4,000 bounding boxes that captured the 
intricate structure of the Khmer script, including its unique 
diacritics and ligatures.

The most important configuration parameters for training the CRAFT 
model are summarized in Table~\ref{tab:craft-training-config}. 
These include the selected training mode, backbone architecture, 
initialization weights, loss function, normalization scheme, and 
optimization hyperparameters. Each setting was carefully selected 
to achieve optimal performance on the Khmer text recognition task.




\begin{table}[H]
\centering
\begin{tabular}{|p{0.4\linewidth}|p{0.55\linewidth}|}
\hline
\textbf{Parameter} & \textbf{Value} \\
\hline
Backbone architecture & VGG \\
Pretrained weights & \texttt{CRAFT.pth} \\
Batch size & 8 \\
Training iterations & 0 to 10,000 \\
Evaluation interval & Every 500 iterations \\
Learning rate & 0.0001 \\
\hline
\end{tabular}
\caption{Key configuration parameters for training the CRAFT model on a custom Khmer dataset 
using weak supervision. The parameters include the training mode, backbone architecture, 
dataset, batch size, training iterations, evaluation interval, learning rate, learning rate decay, 
weight decay, mixed precision, loss function type, negative ratio, minimum negative samples, 
output image size, normalization mean and standard deviation, region and affinity enlargement 
factors, Gaussian kernel initialization size, and Gaussian sigma.}
\label{tab:craft-training-config}
\end{table}


\subsection{Customizing TrOCR Processor}
\label{subsec:customizing-trocr-processor}
        To make the TrOCR model understand Khmer tokens, 
we customized the processor without modifying the original 
model architecture. We developed a CustomKhmerTokenizer 
based on a predefined list of unique Khmer and English characters, 
including special tokens such as \textit{<s>}, \textit{</s>}, and 
\textit{<pad>}, to handle 
the encoding of text into token IDs and the decoding of token IDs 
back into readable text. This tokenizer was then wrapped inside 
a custom processor that mimics the behavior of Hugging Face’s 
TrOCRProcessor, allowing seamless integration with TrOCR’s image 
processing pipeline. By doing so, we enabled the model to work 
with Khmer script during both training and inference, while 
preserving the original TrOCR model’s structure and leveraging 
its pretrained capabilities.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/Customize_processor.png}
    \caption{Architecture of the customized TrOCR pipeline. 
    The original TrOCR model is extended with a custom processor, 
    which includes two additional fully connected layers 
    (FC1 and FC2) tailored for Khmer character decoding.}
    \label{fig:trocr-custom-processor}
\end{figure}



\subsection{Fine-tuning TrOCR Model}
\label{subsec:fine-tuning-trocr-model}
For the TrOCR model, we selected the base model because we were working with a multilingual 
dataset. We wanted the model to have a large parameter size, so we chose the base model for 
this task.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/trocr_model_overflow_training.png}
    \caption{Overview of the TrOCR training process. Text-generated 
    images form the training set, while real-world samples are 
    manually collected for testing and evaluation.}
    \label{fig:trocr-training-pipeline}
\end{figure}

After experimenting with different hyperparameters, we found the desired results. Here are the 
desired hyperparameters: batch size = 1024, learning rate = 0.0001, epoch = 2, dataset = 3.5 
million images. We chose a batch size of 1024 because we wanted the model to generalize well. 
This is a very important hyperparameter because we used to train with 8, 16, 32, 128, 256, 
but it was not generalizing as expected; it was really weak to overfitting. That's why we 
chose 1024.



\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/trocr_overfitting_v1.png}
    \caption{Training and validation loss curves for TrOCR model with batch size 8.}
    \label{fig:trocr-overfitting}
\end{figure}

The graph above illustrates a clear case of overfitting in our TrOCR model training. 
We initially trained the model with a batch size of 8 on our dataset of 3.5 million images. 
As shown in the figure, while the training loss (blue line) continues to decrease, 
the validation loss (orange line) starts to increase, indicating that the model is overfitting 
to the training data. This overfitting occurs because the batch size of 8 is too small relative 
to our large dataset size of 3.5 million images. With such a small batch size, the model learns 
very specific patterns from the training data rather than generalizing well to unseen data. 
This is why we decided to increase the batch size to 1024, which helped improve the model's 
generalization capabilities and reduce overfitting.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/trocr_fine_tuning.png}
    \caption{Training and validation metrics for TrOCR model with batch size 1024, 
    showing Character Error Rate (CER) and Word Error Rate (WER) over training steps. 
    The model demonstrates excellent performance from early training steps, with CER quickly 
    reaching around 0.03 and WER staying below 0.12. This rapid convergence indicates effective 
    learning, likely due to leveraging the pretrained weights from previous training. 
    The larger batch size of 1024 contributes to better generalization compared to smaller batch sizes.}
    \label{fig:trocr-fine-tuning}
\end{figure}

The figure above demonstrates the effectiveness of our fine-tuning approach with a batch size of 1024. 
The model shows remarkable performance from the early stages of training, with the Character 
Error Rate (CER) quickly stabilizing around 0.03 and the Word Error Rate (WER) maintaining 
values below 0.12. This rapid convergence to good performance metrics can be attributed to 
two main factors: (1) the utilization of pretrained weights from previous training iterations, 
which provides a strong foundation for the model, and (2) the larger batch size of 1024, which 
helps the model learn more robust features and generalize better to unseen data. The stable 
performance across both training and validation sets indicates that the model has achieved a 
good balance between learning and generalization, avoiding the overfitting issues we 
encountered with smaller batch sizes.


\section{Evaluation Metrics}
\label{sec:metrics}
Metrics used to evaluate the performance of the OCR system.

\subsection{Detection Metrics (Precision, Recall)}
\label{subsec:detection-metrics}
Text detection evaluation using precision and recall metrics.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/mean_loss_craft.png}
    \caption{Illustration of the mean loss during CRAFT model training, showing the performance 
    improvement over time. The mean loss decreased rapidly in the first 500 iterations, 
    indicating that the model was able to quickly adapt to the training data. The loss then 
    continued to decrease at a slower rate until around 2,000 iterations, at which point 
    the model's performance began to plateau. After 2,000 iterations, the loss remained 
    relatively stable, indicating that the model had converged and was no longer improving.}
    \label{fig:mean-loss-craft}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/iou_craft.png}
    \caption{Illustration of the intersection over union (IOU) vs. recall performance of the CRAFT model 
    during text detection evaluation. The IOU is a measure of how well the bounding box predicted 
    by the model overlaps with the ground truth bounding box, while the recall measures how many of 
    the ground truth bounding boxes are detected by the model. The IOU-recall curve shows that the 
    model can detect most of the text regions with high accuracy. The model reaches a high recall of 
    90\% at an IOU of 0.5, indicating that the model is able to detect most of the text regions even 
    when the predicted bounding box is not perfectly aligned with the ground truth.}
    \label{fig:iou-recall-craft}
\end{figure}


\subsection{Recognition Metrics (Accuracy, CER, WER)}
\label{subsec:recognition-metrics}
For evaluating the text recognition performance of our TrOCR model, we employed three key metrics: Character Error Rate (CER), Word Error Rate (WER), and Accuracy. These metrics provide a comprehensive assessment of the model's recognition capabilities.

Character Error Rate (CER) measures the ratio of incorrect characters to the total number of characters in the ground truth text. It is calculated as:

\begin{equation}
    CER = \frac{S + D + I}{N}
\end{equation}

where $S$ is the number of substitutions, $D$ is the number of deletions, $I$ is the number of insertions, and $N$ is the total number of characters in the ground truth text.

Word Error Rate (WER) is similar to CER but operates at the word level. It measures the ratio of incorrect words to the total number of words in the ground truth text. WER is calculated as:

\begin{equation}
    WER = \frac{S_w + D_w + I_w}{N_w}
\end{equation}

where $S_w$ is the number of word substitutions, $D_w$ is the number of word deletions, $I_w$ is the number of word insertions, and $N_w$ is the total number of words in the ground truth text.

Accuracy is the complement of the error rate, representing the percentage of correctly recognized characters or words. For character-level accuracy:

\begin{equation}
    Accuracy_{char} = 1 - CER
\end{equation}

And for word-level accuracy:

\begin{equation}
    Accuracy_{word} = 1 - WER
\end{equation}

[Add Figure 1 here: A line plot showing the training and validation CER over epochs]
[Add Figure 2 here: A line plot showing the training and validation WER over epochs]
[Add Figure 3 here: A bar chart comparing final CER and WER scores across different test sets]

These metrics provide different perspectives on the model's performance. CER is more sensitive to character-level errors and is particularly useful for evaluating the model's ability to recognize individual characters accurately. WER, on the other hand, provides a higher-level view of the model's performance at the word level, which is often more relevant for practical applications. The accuracy metrics offer an intuitive way to understand the model's overall performance.
