\begin{adjustwidth}{0.2cm}{0.2cm}

    % Khmer Abstract
    \begin{center}
        {\khmerfont\fontsize{15pt}{25pt}\selectfont សង្ខេបសេចក្ដី \par}
    \end{center}
    \phantomsection
    \label{khmer-abstract}
    \vspace{0.5cm}
    \khmernormal
    \small
    នៅក្នុងអត្ថបទស្រាវជ្រាវមួយនេះ យើងនឹងបង្ហាញអំពី ការបំប្លែងរូបភាពឯកសារទៅជាអក្សរ 
    ដែលអាចកែប្រែបាន នៅលើ ភាសាខ្មែរ និងភាសាអង្គគ្លេស។ ចំពោះការបំប្លែងរូបភាពឯកសារ 
    នៃភាសាខ្មែរ ទៅជាអក្សរដែលអាចកែប្រែបាន នៅតែមានបញ្ហាសម្រាប់ OCR System ។ 
    មិនត្រឹមតែភាពខ្វះខាតនៃ ទិន្នន័យ (dataset) សម្រាប់ ឲ្យម៉ូដែលរៀនប៉ុណ្ណោះ ទេ ប៉ុន្តែ 
    ភាពស្មុកស្មាញនៃភាសាខ្មែររឹតតែមានភាពពិបាកក្នុងការចាប់យកអក្សរចេញពីរូបភាពផងដែរ 
    ដូចជា ការសរសេរតម្រួតជាន់លើគ្នា ការចុះដកឃ្លាមានភាពមិនទៀតទាត់ ដែលធ្វើឲ្យការចាប់ 
    យកអក្សរចេញពី រូបភាព មានការលំបាក ខ្លាំង។ ការស្រាវជ្រាវភាគច្រើន គឺគេធ្វើតែទៅលើភាសា 
    អក្សរឡាតាំងតែប៉ុណ្ណោះ ជាប្រភេទ latin-based scripts ដែលជាអក្សរ System មួយប្រភេទ. 
    ដែលមិនសូវមានការសរសេរតម្រួតគ្នាច្រើនតង់។ ការកើនឡើងនៃការប្រើប្រាស់ភាសាចូលគ្នានៅ
    ក្នុងប្រទេសកម្ពុជា មានការកើនឡើងយ៉ាងខ្លាំង នៅពីរទសវត្សរ៍ចុងក្រោយមកនេះ ទៅលើឯក
    សារដូចជា ស្លាកសញ្ញា អត្ថបទការសែត មេរៀន និង ការសន្ទនាផ្សេងៗទៀតដែលបង្កឲ្យមាន
    ភាពស្មុកស្មាញ ខ្លាំងសម្រាប់ការចាប់យកអក្សរ ចេញពីរូបភាពដែលមានអក្សរលាយលំគ្នាច្រើន
    ភាសាបែបនេះ។

    នៅក្នុងការសិក្សាស្រាវជ្រាវមួយនេះ ពួកយើងបានបង្កើត វិធីសាស្ដ្រមួយដែលហៅថា end-to-end 
    OCR approach ដែលធ្វើឡើងសម្រាប់ដោះស្រាយបញ្ហាខាងលើ។ វិធីសាស្ដ្រមួយនេះបានធ្វើការបែង
    ចែកជាពីរផ្នែកធំៗ ដំណាក់កាលទីមួយនោះគឺ ការចាប់យកទីតាំងអក្សរនៅលើរូបភាពដើម្បី បង្កឲ្យ
    មានភាពងាយស្រួលសម្រាប់ ការចាប់យកអក្សរចេញពី រូបភាពឲ្យបានប្រសិទ្ធភាពខ្ពស់ជាងមុន 
    (text-detection)។ នៅក្នុងដំណាក់កាលទី២វិញ គឺការបម្លែងរូបភាពទាំងអស់នោះ ទៅជា
    អត្ថបទដែលអាចធ្វើការកែប្រែបាន (text-recognition)។ ដំណាក់កាលទាំងពីរនេះ គឺបង្កើត
    ឡើងសម្រាប់ធ្វើការដោះស្រាយភាពស្មុកស្មាញទៅលើភាសាខ្មែរ និងការលាយលំភាសាខ្មែរជាមួយ
    នឹងភាសាអង់គ្លេស។
    ដើម្បីបង្រៀនម៉ូដែល និងធ្វើការវាយតម្លៃបាន ដំបូងយើង បានរៀបចំ dataset ដែលមាន 
    high-quality ទាំង real dataset និង synthetic dataset, យើងបានប្រមូល 
    data ទាំងអស់នោះដោយខ្លួនឯង ចំនួន 1000 រូបភាព ហើយបានធ្វើការកំណត់ទីតាំងអក្សរ
    នៅលើរូបភាព ទទួលបាន 13200 ទីតាំងផ្សេងគ្នា។
    ដើម្បីបង្កើន data ឲ្យកាន់តែច្រើន យើងបានប្រើប្រាស់វិធីសាស្ដ្រ text-to-image ដើម្បី
    បង្កើនរូបភាពឲ្យកាន់តែច្រើនជាងមុន ដោយសារតែបើពឹងផ្អែកតែទៅលើ ការប្រមូលម្ដងមួយៗ
    គឺចំណាយពេលវេលានឹងថវិការច្រើន ដូច្នេះមានតែប្រើប្រាស់វិធីសាស្ដ្រ Generate នេះឯង។ 
    បន្ទាប់មកយើងទទួលបានពីការ generate ប្រហែល 8 លាន រូបភាព។

    សម្រាប់ ការកំណត់ទីតាំងនៃអក្សរនៅលើរូបភាព (text detection stage), ពួកយើងបាន
    ប្រើប្រាស់ Craft ម៉ូដែល, ដែលវាល្អសម្រាប់ ការចាប់យកទីតាំងអក្សរ នៅលើរូបភាព។ ពួក
    យើងបាន បង្រៀនម៉ូដែល ទៅលើ dataset manually collected ប្រហែល 1000 
    រូបភាព ដែលអាចកំណត់ទីតាំងអក្សរនៅលើរូបភាពបានល្អ។ យើងទទួលបាន recall 90\%, 
    precision 89\%, និងចុងក្រោយគឺ F1-score 86.8\% ។ 

    នៅក្នុង ការចាប់យកអក្សរចេញពីរូបភាពយើងបានប្រើប្រាស់ TrOCR ម៉ូដែលដែលបាន បង្កើត
    ឡើងដោយក្រុមស្រាវជ្រាវរបស់ microsoft ដែលវាបានប្រើប្រាស់ transformer-based 
    architecture ម៉ូដែលមួយនេះមិនមាន feature ដើម្បី បម្លែងរូបភាពនៅលើភាសាខ្មែរនោះទេ 
    យើងមានតែធ្វើការ កែប្រែ processor របស់ម៉ូដែលមួយនេះ ដើម្បីឲ្យម៉ូដែលមួយនេះ មាន
    សមត្ថភាព បំប្លែងរូបភាពភាសាខ្មែរបាន។ យើងបានបង្រៀនវាទៅលើ dataset ទាំងពីរប្រភព 
    real dataset និង synthetic dataset ដែលទទួលបាន CER 0.02 សម្រាប់ទូទៅ, 
    CER 0.04 សម្រាប់ ភាសាខ្មែរ,  CER 0.01 សម្រាប់ភាសាអង្គគ្លេស និងចុងក្រោយទទួលបាន 
    CER 0.06 សម្រាប់ ការលាយលំអក្សរខ្មែរ ជាមួយនឹងភាសាអង្គគ្លេស។

    ដើម្បីឲ្យការស្រាវជ្រាវមួយនេះ មានការប្រើប្រាស់ជាក់ស្ដែងបាន យើងបាន សរសេរពីរបៀប 
    hosting ការស្រាវជ្រាវមូយនេះ សម្រាប់អនុញ្ញាតឲ្យ មានការ យកទៅប្រើប្រាស់បាន 
    តាមរយៈបង្កើតជា API service សម្រាប់ការតភ្ជាប់ជាមួយនឹងកម្មវិធីផ្សេងៗទៀតបាន។ 
    វាបានបំពេញចន្លោះប្រហោងរវាងការស្រាវជ្រាវនិងការអនុវត្តន៍ក្នុងភាពពិតជាក់ស្ដែងក្នុងសហគមន៍។
    ដែលវាមានសមត្ថភាពស្គាល់អក្សរពហុភាសាខ្មែរ-អង់គ្លេស បានយ៉ាងល្អ។   
    \vspace{2cm}
    
    % English Abstract
    \begin{center}
        {\bfseries\LARGE Abstract \par}
    \end{center}
    \phantomsection
    \label{abstract}
    \vspace{0.5cm}
    \englishfont
    \large
    
    Khmer text recognition presents persistent challenges for OCR 
    systems—not only due to the limited availability of annotated 
    training data, but also because of the language's complex script 
    structure, including stacked characters, overlapping diacritics, 
    and inconsistent font rendering. These features make Khmer 
    particularly difficult for OCR models, Most of OCR systems which 
    are often designed around Latin-based scripts. The increasing 
    use of English alongside Khmer Cambodia’s signage, documents, 
    and digital content further adds to the complexity of building 
    an effective multilingual OCR system.

    In this work, we introduce an end-to-end OCR approach tailored 
    for both Khmer and English, designed specifically for 
    low-resource and multilingual interpretation. Our OCR system 
    follows a two-stage pipeline, consisting of (1) a text detection 
    model and (2) a text recognition model, both optimized to handle 
    the structural and linguistic challenges unique to Khmer script.

    To train and evaluate the system, we first constructed a 
    high-quality dataset combining both real and synthetic data. 
    This included manually collecting 1,000 real-world images and 
    annotating 13,200 text-line bounding boxes. To increase data 
    diversity and simulate real-world variability, we also generated 
    thousands of synthetic images using a text-to-image method, 
    based on a large corpora of Khmer and English sentences rendered 
    with varied fonts, layouts, real world background environments 
    and visual noise.

    For the text detection stage, we adopted the CRAFT model, which 
    is well-suited for detecting irregular and curved text. Trained 
    on our annotated dataset, CRAFT achieved strong results: 90\% 
    recall, 89\% precision, and an F1-score of 86.8\%—demonstrating 
    that accurate detection is achievable even in low-resource 
    settings.

    In the recognition stage, we used TrOCR, a transformer-based 
    OCR architecture. Since TrOCR’s original processor lacked 
    support for Khmer language, we customize it to properly tokenize 
    and decode Khmer characters by build on top of original 
    processor. After training on the combined real and synthetic 
    datasets, the model achieved a character error rate (CER) of 
    0.02 overall—0.04 for Khmer, 0.01 for English, and 0.06 for 
    mixed-language text-line.

    To ensure practical usability, we deployed the system as a 
    production-ready public API, allowing direct integration into 
    real-world applications. Unlike many academic models that 
    remain unused after publication, our deployment helps close 
    the gap between research and application—supporting broader 
    adoption of Khmer-English OCR in multilingual, low-resource 
    environments.



    
    \end{adjustwidth}